import json
import os
import subprocess
import re
from datetime import datetime, timedelta
import argparse

INVENTORY_FILE = 'inventory.json'
COMPRESS_THRESHOLD_DAYS = 5

def load_inventory():
    if not os.path.exists(INVENTORY_FILE):
        print(f"‚ùå Inventory file '{INVENTORY_FILE}' not found.")
        exit(1)
    with open(INVENTORY_FILE) as f:
        return json.load(f)

def run_ssh_command(server, user, ssh_key, cmd):
    ssh_cmd = ["ssh", "-i", ssh_key, f"{user}@{server}", cmd]
    try:
        result = subprocess.run(ssh_cmd, capture_output=True, text=True, timeout=60)
        if result.returncode != 0:
            print(f"‚ùå SSH command failed on {server}: {result.stderr.strip()}")
            return None
        return result.stdout.strip().splitlines()
    except Exception as e:
        print(f"‚ùå SSH command error on {server}: {e}")
        return None

def parse_date_linux(filename):
    # e.g. filename.2025-05-20.log or filename.202505200000.log
    m1 = re.search(r'\.(\d{4}-\d{2}-\d{2})', filename)
    if m1:
        try:
            return datetime.strptime(m1.group(1), '%Y-%m-%d').date()
        except:
            return None
    m2 = re.search(r'\.(\d{12})', filename)
    if m2:
        try:
            return datetime.strptime(m2.group(1)[:8], '%Y%m%d').date()
        except:
            return None
    return None

def parse_date_windows(filename):
    # e.g. filename_ex250521_x.log (YYMMDD after _ex)
    m = re.search(r'_ex(\d{6})', filename)
    if m:
        try:
            dt = datetime.strptime(m.group(1), '%y%m%d').date()
            return dt
        except:
            return None
    return None

def matches_pattern(filename, patterns):
    if not patterns:
        return True
    for pat in patterns:
        pat = pat.strip()
        if not pat:
            continue
        regex = '^' + re.escape(pat).replace(r'\*', '.*').replace(r'\?', '.') + '$'
        if re.match(regex, filename, re.IGNORECASE):
            return True
    return False

def get_files_to_compress(server, os_type, user, ssh_key, base_path, include_patterns, exclude_patterns):
    threshold_date = datetime.now().date() - timedelta(days=COMPRESS_THRESHOLD_DAYS)

    if os_type.lower() == 'linux':
        # Find all files NOT compressed (.gz or .zip) recursively
        cmd = f"find '{base_path}' -type f ! -name '*.gz' ! -name '*.zip'"
        files = run_ssh_command(server, user, ssh_key, cmd)
        if files is None:
            return []
    else:
        # Windows: powershell to get files not ending with .gz or .zip
        ps_cmd = (f"powershell -Command \"Get-ChildItem -Path '{base_path}' -Recurse -File "
                  f"| Where-Object {{$_.Extension -notin '.gz','.zip'}} "
                  f"| Select-Object -ExpandProperty FullName\"")
        files = run_ssh_command(server, user, ssh_key, ps_cmd)
        if files is None:
            return []

    files_to_compress = []

    for f in files:
        fname = os.path.basename(f)

        if include_patterns and not matches_pattern(fname, include_patterns):
            continue
        if exclude_patterns and matches_pattern(fname, exclude_patterns):
            continue

        file_date = None
        if os_type.lower() == 'linux':
            file_date = parse_date_linux(fname)
        else:
            file_date = parse_date_windows(fname)

        if file_date is None:
            print(f"‚ö†Ô∏è Could not parse date from filename '{fname}' on {server}, skipping")
            continue

        if file_date <= threshold_date:
            files_to_compress.append(f)

    return files_to_compress

def compress_file(server, user, ssh_key, filepath, os_type, dry_run):
    # Compress with gzip (Linux) or zip (Windows)
    if dry_run:
        print(f"[DRY-RUN] Would compress {filepath} on {server}")
        return

    if os_type.lower() == 'linux':
        cmd = f"gzip '{filepath}'"
    else:
        # zip command: zip filename.zip filename
        # zip creates zip archive; we create .zip alongside original file
        zip_file = filepath + ".zip"
        # use PowerShell Compress-Archive for Windows: powershell Compress-Archive -Path file -Destination zipfile
        cmd = f"powershell -Command Compress-Archive -Path '{filepath}' -DestinationPath '{zip_file}' -Force; Remove-Item -Force '{filepath}'"

    result = run_ssh_command(server, user, ssh_key, cmd)
    if result is None:
        print(f"‚ùå Failed to compress {filepath} on {server}")
    else:
        print(f"‚úÖ Compressed {filepath} on {server}")

def main():
    parser = argparse.ArgumentParser(description="Compress log files older than 5 days based on filename date.")
    parser.add_argument('--dry-run', action='store_true', help='List files to compress without compressing')
    args = parser.parse_args()

    data = load_inventory()
    if not data:
        print("‚ö†Ô∏è Inventory is empty.")
        return

    for server, info in data.items():
        os_type = info.get('os', 'linux')
        ssh_key = info.get('ssh_key')
        if not ssh_key or not os.path.exists(ssh_key):
            print(f"‚ùå Missing or invalid SSH key for {server}, skipping.")
            continue
        users = info.get('users', {})
        if not users:
            print(f"‚ö†Ô∏è No users found for {server}, skipping.")
            continue
        for user, entries in users.items():
            for entry in entries:
                base_path = entry['log_base_path']
                include_patterns = entry.get('include_patterns', [])
                exclude_patterns = entry.get('exclude_patterns', [])
                print(f"\nüîç Processing {server} ({os_type}) user {user} base_path '{base_path}'")

                files_to_compress = get_files_to_compress(server, os_type, user, ssh_key, base_path, include_patterns, exclude_patterns)
                for f in files_to_compress:
                    compress_file(server, user, ssh_key, f, os_type, args.dry_run)

if __name__ == '__main__':
    main()
